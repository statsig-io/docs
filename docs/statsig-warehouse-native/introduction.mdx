---
title: Getting Started with Statsig Warehouse Native
slug: /statsig-warehouse-native/introduction
sidebar_label: Warehouse Native
description: Set up your first Statsig Warehouse Native project
---

import Button from "@mui/material/Button";
import OutlinedCard from "@site/src/components/OutlinedCard";
import Card from "@mui/material/Card";
import CardActions from "@mui/material/CardActions";
import CardContent from "@mui/material/CardContent";
import CardHeader from "@mui/material/CardHeader";
import Icon from "@mui/material/Icon";
import IconButton from "@mui/material/IconButton";
import Link from "@mui/material/Link";

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

export const ArrowButton = ({ link }) => (
  <IconButton
    style={{
      color: "#194b7d",
      border: "1px solid rgba(0, 0, 0, 0.12)",
      borderRadius: "16px",
      padding: "4px",
    }}
    href={link}
  >
    <Icon
      style={{
        color: "#194b7d",
      }}
    >
      arrow_forward
    </Icon>
  </IconButton>
);

Statsig Warehouse Native is an enterprise-grade experimentation platform that
runs analysis in your data warehouse. It integrates easily with your existing
datasets and any source of experiment assignment data - including a powerful
integration with Statsig's SDKs and real-time logging infrastructure.

Warehouse Native has a shared core feature set with Statsig Cloud. This section of the documentation deals with specifics around setting up and running experiments on top of your warehouse.

### Use Cases for Statsig Warehouse Native

- An end-to-end experimentation platform covering targeting, experiment setup and assignment, and analysis
  - Includes Feature Flagging, Automated/Protected Rollouts, Native Holdouts, Mutual Exlusion, and the analysis tools below
- A modern statistical engine to run analysis on top of existing experiment from third-party or internal systems
  - Statsig provides a complete suite of experiment measurement tools, ranging from user accounting to percentiles, and offers the most experimentation tools on the market - including CUPED, Stratified Sampling, Switchback Tests, and more

Statsig also offers a cloud solution, which is an ideal fit for customers who are primarily using Statsig for Feature Flagging, or don't have a mature data warehouse and/or metric catalog. Our [support team](mailto:support@statsig.com) can help you decide if Statsig Warehouse Native or Statsig Cloud is a better fit for your experimentation needs.

## How It All Works

Statsig Warehouse Native runs experimentation compute jobs in your data warehouse, leveraging your core datasets in order to calculate metrics and enrich experiment analysis that much your existing source of truth.

### SDKs

Using SDKs with Statsig Warehouse Native is identical to integrating with Statsig Cloud. Statsig's SDKs cover dozens of languages, and are used by thousands of customers. The basic steps are to:

- Set up targeting and experiments in the Statsig console
- Initialize the Statsig SDK on a client or server-side application
- Call the Statsig SDK to get user targeting and assignment
  - Provide a logging callback to log to your own warehouse, or
  - Leverage Statsig's real-time infra to get instant diagnostics and roll out features safely with real-time guardrail reports

The resulting assignment (and optional event logging) data ends up in your warehouse,Â where it can be connected to other datasets in order to generate experiment analyses. If you choose to log to Statsig, data is exported on-demand for real-time analysis, as well as in hourly/daily batch jobs.

### Analysis

Statsig's data analysis runs in your data warehouse. All of the queries, intermediate datasets, and results that Statsig runs will be available in your warehouse for auditing and any custom analysis.

Running experiments looks like:

- Connecting Statsig to your warehouse
- Creating metrics by pointing to input data and configuring experiment metrics
- Creating an experiment and logging exposures with Statsig, or pointing to existing assignments that you already have
- Stating a hypothesis, and picking scorecard metrics to evaluate your hypothesis
- Running a Pulse analysis to test your hypotheses and measure the impact your change had on your scorecard metrics
- Using Statsig's advanced diagnostics, explore tools, and meta-analysis to start building and sharing organizational knowledge

In addition to experiment analysis, Statsig also offers Metrics Explorer - a powerful tool to visualize your experiment metrics over your entire population and drill down into user behavior. This is part of a broad suite of product observability that comes with Statsig as an experimentation platform, with features like Session Replay, advanced filtering, and dashboards.

## Next Steps

:::info
Don't get blocked! We love to help people use Statsig. Reach out to support or chat with us in Slack!
:::

Check our getting started guides to start running or analyzing an experiment in minutes.

<div
  style={{
    display: "flex",
    flexWrap: "wrap",
  }}
>
  <OutlinedCard
    title="Connect Your Warehouse"
    icon="warehouse"
    description="Connect Statsig to your warehouse to start analyzing experiments"
    link="guides/connect"
  ></OutlinedCard>
  <OutlinedCard
    title="Create Metrics"
    icon="speed"
    description="Connect to a metric source and configure metrics for analysis in Statsig"
    link="guides/metric-sources"
  ></OutlinedCard>
  <OutlinedCard
    title="Start an Experiment"
    icon="science"
    description="Connect to your assignment data in minutes, and start testing hypotheses"
    link="guides/assignment-sources"
  ></OutlinedCard>
</div>
