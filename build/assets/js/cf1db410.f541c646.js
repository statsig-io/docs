"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[43162],{13685:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var i=n(74848),a=n(28453);const o={title:"Monitoring your Contextual MAB",sidebar_label:"Monitoring",slug:"/autotune/contextual/monitoring",keywords:["owner:vm"],last_update:{date:new Date("2025-09-18T00:00:00.000Z")}},r="Linked Experiments",s={id:"autotune/contextual/monitoring",title:"Monitoring your Contextual MAB",description:"There are three primary ways we recommend you monitor autotune performance.",source:"@site/docs/autotune/contextual/monitoring.md",sourceDirName:"autotune/contextual",slug:"/autotune/contextual/monitoring",permalink:"/autotune/contextual/monitoring",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/autotune/contextual/monitoring.md",tags:[],version:"current",lastUpdatedAt:17581536e5,frontMatter:{title:"Monitoring your Contextual MAB",sidebar_label:"Monitoring",slug:"/autotune/contextual/monitoring",keywords:["owner:vm"],last_update:{date:"2025-09-18T00:00:00.000Z"}},sidebar:"cloud",previous:{title:"Getting Started",permalink:"/autotune/contextual/getting-started"},next:{title:"Methodology",permalink:"/autotune/contextual/methodology"}},u={},c=[];function l(e){const t={code:"code",em:"em",h1:"h1",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"There are three primary ways we recommend you monitor autotune performance."}),"\n",(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"linked-experiments",children:"Linked Experiments"})}),"\n",(0,i.jsx)(t.p,{children:"The best way to evaluate if a bandit is working is seeing if it drives more of the targeted behavior via baseline experience. You can easily set up and link an a/b test in Statsig to evaluate this, and this will also let you monitor other user behaviors and guardrail metrics."}),"\n",(0,i.jsx)(t.p,{children:"This is the gold standard of measurement and is highly encouraged."}),"\n",(0,i.jsx)(t.p,{children:"Standard practice is to wrap the autotune in a experiment with a binary parameter, either as 50/50 or a 90/10 holdback.  You can link the experiment to the autotune to get the results on the autotune page. In code, this might look like:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"experiment_value = statsig.get_experiment('wrapping_experiment').get('flag')\ndefault_param = '...\"\nif(experiment_value):\n  param = statsig.get_experiment('autotune').get('param_name')\nelse:\n  param = default_param\n\n# use param in code\n"})}),"\n",(0,i.jsx)(t.p,{children:"You would start this experiment at the same time that you launch your autotune."}),"\n",(0,i.jsx)(t.h1,{id:"success-rate",children:"Success Rate"}),"\n",(0,i.jsxs)(t.p,{children:["Statsig will track the cumulative and daily success rate of your variants over time. This can be tricky to interpret. It may be the case that variant A has lower CTR, but the users being served variant A ",(0,i.jsx)(t.em,{children:"would have had"})," even lower CTR on other variants. We generally recommend using this for tracking and for understanding, and seeing if there are good or bad outliers in your variants."]}),"\n",(0,i.jsx)(t.h1,{id:"traffic-allocation",children:"Traffic Allocation"}),"\n",(0,i.jsx)(t.p,{children:"Traffic allocation shows you where Statsig is sending users who see your Autotune. This is a helpful debug view and can help you identify if a variant is dominating traffic or is not receiving any traffic."}),"\n",(0,i.jsx)(t.h1,{id:"model-features",children:"Model Features"}),"\n",(0,i.jsx)(t.p,{children:"Statsig tracks and surfaces coefficients and feature importance; this can be very useful for understanding which features might be worth further study, or which populations may have unmet needs in your product."}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:'Importance is an estimate of the influence of a feature on the outcome; in layman\'s terms, this is "how important" the feature is to the prediction'}),"\n",(0,i.jsx)(t.li,{children:"A positive coefficient means that feature leads to an outcome being more likely (or for continuous outcome spaces is associated with a higher outcome). A negative coefficient means the outcome is less likely, or is associated with a lower continuous outcome."}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var i=n(96540);const a={},o=i.createContext(a);function r(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);