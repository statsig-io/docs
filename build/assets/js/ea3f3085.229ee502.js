"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[8582],{8289:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>l});var s=n(74848),i=n(28453);const r={sidebar_label:"A/A Test with Sidecar",title:"Running an A/A (aa) Test using Sidecar",keywords:["owner:brock"],last_update:{date:new Date("2025-09-18T00:00:00.000Z")}},a=void 0,o={id:"guides/aa-sidecar",title:"Running an A/A (aa) Test using Sidecar",description:"In this guide, we will walk you through how to leverage Statsig\u2019s sidecar to run an A/A test on your product.",source:"@site/docs/guides/aa-sidecar.mdx",sourceDirName:"guides",slug:"/guides/aa-sidecar",permalink:"/guides/aa-sidecar",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/guides/aa-sidecar.mdx",tags:[],version:"current",lastUpdatedAt:17581536e5,frontMatter:{sidebar_label:"A/A Test with Sidecar",title:"Running an A/A (aa) Test using Sidecar",keywords:["owner:brock"],last_update:{date:"2025-09-18T00:00:00.000Z"}},sidebar:"cloud",previous:{title:"GTM Integration",permalink:"/guides/sidecar-experiments/integrating-gtm"},next:{title:"Overview",permalink:"/product-analytics/overview"}},c={},l=[{value:"Why run an A/A (aa) test?",id:"why-run-an-aa-aa-test",level:2},{value:"How to run an A/A test",id:"how-to-run-an-aa-test",level:2},{value:"Step 1: Create a new Experiment in Sidecar",id:"step-1-create-a-new-experiment-in-sidecar",level:3},{value:"Step 2: Configure Experiment Scorecard in Statsig Console",id:"step-2-configure-experiment-scorecard-in-statsig-console",level:3},{value:"Step 3: Review A/A test results",id:"step-3-review-aa-test-results",level:3}];function d(e){const t={a:"a",admonition:"admonition",h2:"h2",h3:"h3",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:"In this guide, we will walk you through how to leverage Statsig\u2019s sidecar to run an A/A test on your product."}),"\n",(0,s.jsx)(t.admonition,{type:"info",children:(0,s.jsxs)(t.mdxAdmonitionTitle,{children:["info This guide assumes that you have successfully set up and configured Statsig Sidecar. For a step-by-step guide on how to do this, see our ",(0,s.jsx)(t.a,{href:"/guides/sidecar-experiments/setup",children:"\u201csetting up Sidecar\u201d"})," guide."]})}),"\n",(0,s.jsx)(t.h2,{id:"why-run-an-aa-aa-test",children:"Why run an A/A (aa) test?"}),"\n",(0,s.jsx)(t.p,{children:"There are many reasons to run an A/A test, one of the most common being to validate a new experimentation engine you may be integrating with (in this case Statsig).  For new users just getting started with Statsig, we often recommend running an A/A test to provide a \u201clow-stakes\u201d first test environment, ensuring that you\u2019ve got your metrics set up correctly and are seeing exposures flowing through as expected before kicking off your first real A/B test."}),"\n",(0,s.jsx)(t.h2,{id:"how-to-run-an-aa-test",children:"How to run an A/A test"}),"\n",(0,s.jsx)(t.h3,{id:"step-1-create-a-new-experiment-in-sidecar",children:"Step 1: Create a new Experiment in Sidecar"}),"\n",(0,s.jsx)(t.p,{children:"Navigate to the page on your website that you want to run an A/A Test. Open the Statsig Side car extension and click on 'New Experiment'. Fill in the title of your A/A test."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Sidecar experiment setup interface",src:n(90712).A+"",width:"364",height:"651"})}),"\n",(0,s.jsx)(t.p,{children:"Then, determine of the URI filter (i.e. All Pages, contains, etc.). After you have configured the URI, it is time to set up the variants."}),"\n",(0,s.jsx)(t.p,{children:"With the variant 'Control', pick an action. In this example we are simply changing the content of an element, specifically the title, 'Getting Started is Simple'."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Sidecar variant configuration screen",src:n(23495).A+"",width:"2772",height:"1334"})}),"\n",(0,s.jsx)(t.p,{children:"Repeating the step above, you'll do the exact same action for the variant 'Test'. Your set up should look like the following."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Sidecar A/A test final configuration",src:n(52935).A+"",width:"471",height:"889"})}),"\n",(0,s.jsx)(t.p,{children:"From there, all you'll need to do is click 'Publish', this will push out the experiment to Statsig as a draft."}),"\n",(0,s.jsx)(t.h3,{id:"step-2-configure-experiment-scorecard-in-statsig-console",children:"Step 2: Configure Experiment Scorecard in Statsig Console"}),"\n",(0,s.jsx)(t.p,{children:"Once the experiment is pushed out to end users, you will need to edit the scorecard to your experiment within the console. Navigate to the console, click on the Experiments tab, and go into the experiment you just created."}),"\n",(0,s.jsx)(t.p,{children:"In the Setup tab, you can fill out the scorecard for the experiment Hypothesis, and any primary metrics you are interested in watching. While Statsig will show you experiment results for all your metrics, these key metrics represent your hypothesis for the experiment. Establishing a hypothesis upfront ensures that the experiment serves to improve your understanding of users rather than simply serving data points to bolster the case for shipping or not shipping your experiment."}),"\n",(0,s.jsx)(t.p,{children:"In the Allocation and Targeting section, for an AA test, we recommend to allocate 100% of users to the experiment while targeting everyone."}),"\n",(0,s.jsx)(t.p,{children:"Then, make sure to save and push your experiment. Your test is now set up to start measuring metrics associated with the A/A Test!"}),"\n",(0,s.jsx)(t.h3,{id:"step-3-review-aa-test-results",children:"Step 3: Review A/A test results"}),"\n",(0,s.jsxs)(t.p,{children:["Within 24 hours of starting your experiment, you'll see the cumulative exposures in the ",(0,s.jsx)(t.strong,{children:"Pulse Results"})," tab of your experiment."]}),"\n",(0,s.jsxs)(t.p,{children:["his will break down your logged exposures (as well as the distribution of the logged exposures). If something looks off, check the ",(0,s.jsx)(t.strong,{children:"Diagnostics"})," tab for more granular, day-by-day exposure breakdowns at both the Checks and User level."]}),"\n",(0,s.jsxs)(t.p,{children:["In the ",(0,s.jsx)(t.strong,{children:"Scorecard"})," panel, you can see the full picture of how all your tagged metrics are performing."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/101903926/163248267-7bd7419a-59e0-4d58-b8e5-8ace95ed74d9.png",alt:"pulse_results_empty"})}),"\n",(0,s.jsx)(t.p,{children:"What should you expect to see?"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Exposures"}),"- make sure you\u2019re seeing exposures flowing through as expected from your product. If you\u2019re not seeing exposures, use the ",(0,s.jsx)(t.strong,{children:"Diagnostics"})," tab and the ",(0,s.jsx)(t.strong,{children:"Exposure Stream"})," to debug"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Pulse results"}),"- roughly 5% of your metrics in Pulse should be showing a statistically significant change due to the 95% confidence interval of Statsig\u2019s stats engine"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"We recommend running your A/A long enough to reach most of your weekly active users, or at least a week."})]})}function u(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},52935:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sidecar_aa_final-770fcefff04e714b319f251a84216282.png"},23495:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sidecar_aa_select-7cd8bd92e3a8ea7ae2e634f71c3e3612.png"},90712:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sidecar_aa_setup-2da5b6834c979d23448446d83c317f24.png"},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>o});var s=n(96540);const i={},r=s.createContext(i);function a(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);