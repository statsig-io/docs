"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[33226],{57765:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>u});var i=n(74848),s=n(28453);const o={title:"Count Distinct Metrics",sidebar_label:"Count Distinct",keywords:["owner:vm"],last_update:{date:new Date("2025-09-18T00:00:00.000Z")}},a=void 0,r={id:"statsig-warehouse-native/metrics/count-distinct",title:"Count Distinct Metrics",description:"Summary",source:"@site/docs/statsig-warehouse-native/metrics/count-distinct.md",sourceDirName:"statsig-warehouse-native/metrics",slug:"/statsig-warehouse-native/metrics/count-distinct",permalink:"/statsig-warehouse-native/metrics/count-distinct",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/statsig-warehouse-native/metrics/count-distinct.md",tags:[],version:"current",lastUpdatedAt:17581536e5,frontMatter:{title:"Count Distinct Metrics",sidebar_label:"Count Distinct",keywords:["owner:vm"],last_update:{date:"2025-09-18T00:00:00.000Z"}},sidebar:"warehouse",previous:{title:"Count",permalink:"/statsig-warehouse-native/metrics/count"},next:{title:"Unit Count (One-Time Event)",permalink:"/statsig-warehouse-native/metrics/unit-count-once"}},c={},u=[{value:"Summary",id:"summary",level:2},{value:"Use Cases",id:"use-cases",level:3},{value:"Calculation",id:"calculation",level:2},{value:"Methodology Notes",id:"methodology-notes",level:3},{value:"Options",id:"options",level:2},{value:"Limits",id:"limits",level:2}];function l(e){const t={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(t.p,{children:"Count distinct metrics calculate the unique values observed in a column of a metric source. This is calculated per-unit, so the total is the number of unique unit-value pairs."}),"\n",(0,i.jsxs)(t.admonition,{type:"warning",children:[(0,i.jsxs)(t.p,{children:["Count-distinct metrics are more expensive to compute than ",(0,i.jsx)(t.a,{href:"./count",children:"count"})," or ",(0,i.jsx)(t.a,{href:"./unit-count-once",children:"unique unit count"})," metrics, especially for very long experiments."]}),(0,i.jsx)(t.p,{children:"If you want to count distinct occurrences of the experiment's unit of assignment (e.g. the user_id in a user_id experiment), you should use a unit_count metrics instead. This achieves the same result, but more efficiently calculates and stores the metric data."}),(0,i.jsx)(t.p,{children:"In many cases a count metric serves as a close proxy to count-distinct; you can also set up a data source to track unique instances of a key to avoid re-running the distinct operation across experiment analyses."})]}),"\n",(0,i.jsx)(t.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,i.jsx)(t.p,{children:"Count distinct metrics have two primary use cases:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Measuring interactions and surface area. For example, you might to count the number of entities a user has engaged with on a video streaming platform, or measure if your new recommendation engine increases the diversity of products clicked"}),"\n",(0,i.jsx)(t.li,{children:'As a denominator in ratio metrics, especially common when you want to normalize by a unit other than your experiment\'s unit of analysis. For example, a B2B experiment might run an experiment at the company level, but measure "Clicks per USER" by making a ratio metric of COUNT(clicks)/COUNT_DISTINCT(user_id).'}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"calculation",children:"Calculation"}),"\n",(0,i.jsx)(t.p,{children:"At the unit level, count distinct metrics use COUNT_DISTINCT on their input column."}),"\n",(0,i.jsx)(t.p,{children:"At the group level, the mean is calculated as the SUM of the unit-level COUNT_DISTINCTs, divided by the count of UNIQUE UNITS exposed to the experiment."}),"\n",(0,i.jsx)(t.p,{children:"This would look like the SQL below:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'-- Unit Level\nSELECT\n  source_data.unit_id,\n  exposure_data.group_id,\n  COUNT(distinct source_data.value_column) as value\nFROM source_data\nJOIN exposure_data\nON\n  -- Only include users who saw the experiment\n  source_data.unit_id = exposure_data.unit_id\n  -- Only include data from after the user saw the experiment\n  -- In this case exposure_data is already deduped to the "first exposure"\n  AND source_data.timestamp >= exposure_data.timestamp\nGROUP BY\n  source_data.unit_id,\n  exposure_data.group_id;\n\n-- Experiment\nSELECT\n  group_id,\n  COUNT(distinct unit_id) total_units\nFROM exposure_data\nGROUP BY group_id;\n\n-- Group Level\nSELECT\n  group_id,\n  SUM(value)/SUM(total_units) as mean\nFROM unit_data\nJOIN group_data\nUSING (group_id)\nGROUP BY group_id;\n'})}),"\n",(0,i.jsx)(t.h3,{id:"methodology-notes",children:"Methodology Notes"}),"\n",(0,i.jsx)(t.p,{children:"In the metrics page view, we use APPROX_COUNT_DISTINCT (or equivalent) to avoid massive compute jobs on analytical count distinct, and because the approximate error becomes acceptably small for the topline estimate. For experiment result loads, the calculation is analytical and exact to avoid jitter or bias from approximation error."}),"\n",(0,i.jsx)(t.h2,{id:"options",children:"Options"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Metric Breakdowns","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"You can configure Metadata Columns to group results by, getting easy access to dimensional views in pulse results"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Winsorization","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Specify a lower and/or upper percentile bound to winsorize at. All values below the lower threshold, or above the upper threshold, will be clamped to that threshold to reduce the outsized impact of outliers on your analysis"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["CUPED","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Specify if you want to calculate CUPED, and the lookback window for CUPED's pre-experiment data inputs"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Thresholding","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Turn this metric into a 1/0 unit count metric counting if the unit's total count equals to or surpasses (>=) a given threshold"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"/statsig-warehouse-native/features/cohort-metrics",children:"Cohort Windows"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["You can specify a window for data collection after a unit's exposure. For example, a 0-1 day cohort window would only count actions from days 0 and 1 after a unit was exposed to an experiment","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Only include units with a completed window"})," can be selected to remove units out of pulse analysis for this metric until the cohort window has completed"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"limits",children:"Limits"}),"\n",(0,i.jsx)(t.p,{children:"Count distinct metrics are available in most experiments, except for Switchbacks."})]})}function d(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>r});var i=n(96540);const s={},o=i.createContext(s);function a(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);