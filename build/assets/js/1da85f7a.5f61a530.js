"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[33618],{93353:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var i=n(74848),s=n(28453);const a={title:"Retention Metrics",sidebar_label:"Retention",keywords:["owner:vm"],last_update:{date:new Date("2025-09-18T00:00:00.000Z")}},r=void 0,o={id:"statsig-warehouse-native/metrics/retention",title:"Retention Metrics",description:"Summary",source:"@site/docs/statsig-warehouse-native/metrics/retention.md",sourceDirName:"statsig-warehouse-native/metrics",slug:"/statsig-warehouse-native/metrics/retention",permalink:"/statsig-warehouse-native/metrics/retention",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/statsig-warehouse-native/metrics/retention.md",tags:[],version:"current",lastUpdatedAt:17581536e5,frontMatter:{title:"Retention Metrics",sidebar_label:"Retention",keywords:["owner:vm"],last_update:{date:"2025-09-18T00:00:00.000Z"}},sidebar:"warehouse",previous:{title:"First/Latest Value",permalink:"/statsig-warehouse-native/metrics/latest-value"},next:{title:"Max/Min",permalink:"/statsig-warehouse-native/metrics/max-min"}},d={},l=[{value:"Summary",id:"summary",level:2},{value:"Use Cases",id:"use-cases",level:3},{value:"Setup and Definition",id:"setup-and-definition",level:3},{value:"Calculation",id:"calculation",level:2},{value:"Methodology Notes",id:"methodology-notes",level:3},{value:"Options",id:"options",level:2}];function c(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(t.p,{children:"Retention metrics measure the rolling retention rate across a configured time window for a given event - or between two different events."}),"\n",(0,i.jsx)(t.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,i.jsx)(t.p,{children:'Retention metrics are an easy and powerful way to measure user stickiness, conversion, and growth over the duration of experiments and holdouts. For example, this retention metric can evaluate the change of "Current User Retention", "Notification Retention", "Video Viewer Retention" or more over the course of the experiment, and be broken down in timeseries and days-since-exposure views to understand how this shifted over time.'}),"\n",(0,i.jsx)(t.p,{children:"It's fairly typical for platforms to limit retention metrics to checking if a unit was active between days X and X+Y since exposure. This is useful for new-user or marketing experiments, but is incomplete and is notably less useful for experiments targeted at an existing userbase."}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://www.lennysnewsletter.com/p/how-duolingo-reignited-user-growth",children:"This article in Lenny's newsletter"})," provides a view into how people are using these metrics to drive user growth."]}),"\n",(0,i.jsx)(t.p,{children:"We highly recommend using this metric type for any change aimed at increasing user stickiness - e.g. anything that touches notifications, reactivation campaigns, or quality work."}),"\n",(0,i.jsx)(t.h3,{id:"setup-and-definition",children:"Setup and Definition"}),"\n",(0,i.jsx)(t.p,{children:'Retention metrics are defined with a duration and a lookback window. The period is measured backwards from the end - so "Lookback = 7, Duration = 14" or L7D14 would measure the week ending 14 days after the start event'}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:"https://github.com/user-attachments/assets/cce09282-0a9b-4218-b823-7416f03ef387",alt:"Retention Setup"})}),"\n",(0,i.jsx)(t.p,{children:"This is a rolling calculation. Each day a user triggers the start event, they get a 1 in their metric denominator. If they are active in the corresponding completion window, their numerator will be 1 for that day."}),"\n",(0,i.jsx)(t.p,{children:"Only days with completed windows will be included in pulse. For example if the duration is 7, the last week of data is excluded from pulse to avoid diluting the metric since an L3D7 metric would always have a numerator of 0 for those days."}),"\n",(0,i.jsxs)(t.p,{children:["Using the ",(0,i.jsx)(t.code,{children:"allow cohort metrics to mature after experiment end"})," setting in advanced experiment settings allows for post-experiment data to complete the analysis, meaning units exposed later in the analysis can be included. This is appropriate in cases where the treatment is one-time and doesn't need to be re-applied in order to impact users."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:"https://github.com/user-attachments/assets/2a9d8731-1c28-4c59-a0fe-3c1e7586c129",alt:"Retention Explanation"})}),"\n",(0,i.jsx)(t.h2,{id:"calculation",children:"Calculation"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"-- Denominator - 1/0 flag for activity on a day\nWITH denominator AS (\n    SELECT\n        source_data.unit_id,\n        source_data.date,\n        exposure_data.group_id,\n        MAX(1) as denominator\n    FROM source_data\n    JOIN exposure_data\n    ON\n      -- Only include users who saw the experiment\n      source_data.unit_id = exposure_data.unit_id\n      -- Only include data from after the user saw the experiment\n      -- In this case exposure_data is already deduped to the \"first exposure\"\n      AND source_data.timestamp >= exposure_data.timestamp\n    WHERE <start_filter>\n    GROUP BY ALL;\n),\n\n-- Numerator Candidates - 1/0 flag for success activity on a day\n-- Note by default this is equivalent to the denominator CTE\nnumerator_candidates AS (\n    SELECT\n        source_data.unit_id,\n        source_data.date,\n        exposure_data.group_id,\n        MAX(1) as denominator\n    FROM source_data\n    JOIN exposure_data\n    ON\n      -- Only include users who saw the experiment\n      source_data.unit_id = exposure_data.unit_id\n      -- Only include data from after the user saw the experiment\n      -- In this case exposure_data is already deduped to the \"first exposure\"\n      AND source_data.timestamp >= exposure_data.timestamp\n    WHERE <success_filter>\n    GROUP BY ALL\n),\n\n-- Numerators, deduplicated - 1/0 flag for success per denominator\n-- Now we have a 1-0 numerator flag per denominator-day\njoined_data AS (\n    SELECT\n        denominator.unit_id,\n        denominator.date,\n        den.group_id,\n        1 as denominator\n        MAX(CASE WHEN numerator_candidates.unit_id IS NOT NULL THEN 1 ELSE 0 END) as numerator\n    FROM denominator\n    LEFT JOIN numerator_candidates\n    ON denominator.unit_id = numerator_candidates.unit_id\n    AND numerator_candidates.date BETWEEN\n        denominator.date + INTERVAL '<END - (LENGTH - 1)>' DAY\n        AND denominator.date + INTERVAL '<LENGTH>' DAY\n    GROUP BY ALL\n)\n\n-- Group Level\nSELECT\n  group_id,\n  SUM(denominator) as unit_days_started,\n  SUM(numerator) as unit_days_completed,\n  SUM(numerator)/SUM(denominator) as mean\nFROM joined_data\nGROUP BY ALL\n"})}),"\n",(0,i.jsx)(t.h3,{id:"methodology-notes",children:"Methodology Notes"}),"\n",(0,i.jsxs)(t.p,{children:["Retention metrics are ",(0,i.jsx)(t.a,{href:"/statsig-warehouse-native/metrics/ratio",children:"ratio metrics"})," for the purposes of pulse calculations; the only distinction is that the metric date is attributed to the denominator date."]}),"\n",(0,i.jsx)(t.p,{children:"The ratio components for retention metrics reflect the rolling metric definition:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:'the denominator is the average number of days per user where the "retention start" event was triggered'}),"\n",(0,i.jsx)(t.li,{children:'the numerator is the average number of days per user where a "retention start" event had a corresponding "retention end" event in its retention period.'}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"options",children:"Options"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Metric Breakdowns","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"You can configure Metadata Columns to group results by, getting easy access to dimensional views in pulse results"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Retention Lookback Window (Days)","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:'The length of the "Completion Event" collection window'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Retention Period End (Days)","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"When to stop measuring retention completion events"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Use a different start and completion event for retention calculations","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:'Choose a secondary event for completion windows. By default, retention measures a behavior\'s retention to itself. Toggling this allows you to measure a secondary event instead - for example if you have user accounting flags you could measure "IS CHURNED" -> "IS REACTIVATED" as well as "IS REACTIVATED" -> "IS CHURNED" to measure both reactivation and falloff of a long-term marketing test.'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Metric Breakdowns","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"You can configure Metadata Columns to group results by, getting easy access to dimensional views in pulse results"}),"\n"]}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var i=n(96540);const s={},a=i.createContext(s);function r(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);