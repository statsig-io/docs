"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[98993],{46575:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var n=i(74848),s=i(28453);const a={title:"Pre-Experiment Bias",sidebar_label:"Pre-Experiment Bias",slug:"/stats-engine/pre-experiment-bias",keywords:["owner:vm"],last_update:{date:new Date("2025-09-18T00:00:00.000Z")}},r=void 0,o={id:"stats-engine/pre-experiment-bias",title:"Pre-Experiment Bias",description:"In some cases, users in two experiment groups can have meaningfully different average behaviors before your experiment applies any intervention to them. If this difference is maintained after your experiment starts, it's possible that experiment analysis will attribute that pre-existing difference to your intervention.",source:"@site/docs/stats-engine/pre-experiment-bias.mdx",sourceDirName:"stats-engine",slug:"/stats-engine/pre-experiment-bias",permalink:"/stats-engine/pre-experiment-bias",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/stats-engine/pre-experiment-bias.mdx",tags:[],version:"current",lastUpdatedAt:17581536e5,frontMatter:{title:"Pre-Experiment Bias",sidebar_label:"Pre-Experiment Bias",slug:"/stats-engine/pre-experiment-bias",keywords:["owner:vm"],last_update:{date:"2025-09-18T00:00:00.000Z"}},sidebar:"cloud",previous:{title:"Managing SRM",permalink:"/guides/srm"},next:{title:"Bot Traffic",permalink:"/feature-flags/bots"}},l={},c=[{value:"How it works",id:"how-it-works",level:3},{value:"What to Do",id:"what-to-do",level:3}];function d(e){const t={a:"a",h3:"h3",img:"img",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.p,{children:['In some cases, users in two experiment groups can have meaningfully different average behaviors before your experiment applies any intervention to them. If this difference is maintained after your experiment starts, it\'s possible that experiment analysis will attribute that pre-existing difference to your intervention.\nThis can make a result seem more or less "good" or "bad" than it really is.\n',(0,n.jsx)(t.a,{href:"/stats-engine/methodologies/cuped",children:"CUPED"})," is helpful in addressing this bias, but can't totally account for it."]}),"\n",(0,n.jsx)(t.p,{children:"Additionally, some metrics like retention are not viable candidates for CUPED and can't be easily adjusted."}),"\n",(0,n.jsx)(t.p,{children:"Statsig proactively measures the pre-experiment values of all scorecard metrics for all experiment groups, and determines if the values are significantly different and could cause misinterpretations.\nIf bias is detected, users are notified and a warning is placed on relevant Pulse results."}),"\n",(0,n.jsx)(t.h3,{id:"how-it-works",children:"How it works"}),"\n",(0,n.jsx)(t.p,{children:'Statsig provides a "Days Since Exposure" view to help identify novelty effects and existing pre-experiment effects. For example, the test group of the experiment below had a consistently higher mean\nthan the control group in the week before exposure for this metric'}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:"https://user-images.githubusercontent.com/102695539/246545035-22ff2db6-9c08-4227-a53d-8faa8feb5e92.png",alt:"Pre-experiment bias visualization showing test group with consistently higher mean than control group"})}),"\n",(0,n.jsxs)(t.p,{children:["Statsig detects this bias by running the standard ",(0,n.jsx)(t.a,{href:"/pulse/read-pulse",children:"pulse"})," calculation on the pre-experiment term (looking back one week in cloud, and your configured CUPED lookback window in Warehouse Native), and calculating the p-value for the null hypothesis that the groups are identical.\nRelevant results will be flagged according to logic which balances awareness and false positives stemming from high numbers of scorecard metrics or groups."]}),"\n",(0,n.jsx)(t.h3,{id:"what-to-do",children:"What to Do"}),"\n",(0,n.jsx)(t.p,{children:"Pre-experiment bias can occur by chance and is not always a major issue."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"If the total delta is small, it may not meaningfully influence your interpretation of results"}),"\n",(0,n.jsx)(t.li,{children:"If CUPED can account for the bias, then the bias should not impact your results"}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"In many cases, you can just use this warning as that - a warning - and proceed while treating impacted metrics with a grain of salt.\nThis is often the correct path forward if the metric is not critical to the experiment, or if you care more about the directional movement than the exact number.\nAdditionally, more time may alleviate the bias if there's no systemic source (which is generally the case), as the bias will be diluted by additional new users."}),"\n",(0,n.jsx)(t.p,{children:"However, if the metric is critical to your analysis and you care about the exact numerical value, you may want to consider resalting and restarting this experiment."})]})}function u(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>o});var n=i(96540);const s={},a=n.createContext(s);function r(e){const t=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(a.Provider,{value:t},e.children)}}}]);