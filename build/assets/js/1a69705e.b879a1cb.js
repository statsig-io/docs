"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[26817],{58178:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>l});var s=a(74848),n=a(28453);const r={title:"Getting Started",sidebar_label:"Getting Started",slug:"/ai-evals/getting-started",last_update:{date:new Date("2025-07-25T00:00:00.000Z")}},i=void 0,o={id:"ai-evals/getting-started",title:"Getting Started",description:"Create/analyze an offline eval in 10 minutes",source:"@site/docs/ai-evals/getting-started.md",sourceDirName:"ai-evals",slug:"/ai-evals/getting-started",permalink:"/ai-evals/getting-started",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/ai-evals/getting-started.md",tags:[],version:"current",lastUpdatedAt:17534016e5,frontMatter:{title:"Getting Started",sidebar_label:"Getting Started",slug:"/ai-evals/getting-started",last_update:{date:"2025-07-25T00:00:00.000Z"}},sidebar:"cloud",previous:{title:"Overview",permalink:"/ai-evals/overview"},next:{title:"Prompts",permalink:"/ai-evals/prompts"}},c={},l=[{value:"Create/analyze an offline eval in 10 minutes",id:"createanalyze-an-offline-eval-in-10-minutes",level:2}];function d(e){const t={a:"a",h2:"h2",p:"p",strong:"strong",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h2,{id:"createanalyze-an-offline-eval-in-10-minutes",children:"Create/analyze an offline eval in 10 minutes"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"1. Create a Prompt within Statsig"})}),"\n",(0,s.jsxs)(t.p,{children:["This captures the instruction you provide to an LLM to accomplish your task. You can now use the Statsig ",(0,s.jsx)(t.a,{href:"/server-core/node-core#getting-a-prompt",children:"Node"})," or ",(0,s.jsx)(t.a,{href:"/server-core/python-core/#getting-a-prompt",children:"Python"}),' Server Core SDKs to retrieve this prompt within your app and use it. You can create multiple versions of the prompt as you iterate, and choose which one is "live" (retrieved by the SDK).']}),"\n",(0,s.jsx)("img",{alt:"image",src:"https://github.com/user-attachments/assets/a17b3c4d-2126-4dfe-8d4b-d40b1838f878"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"2. Create a dataset you can use to evaluate LLM completions for your prompt"})}),"\n",(0,s.jsx)(t.p,{children:"For the example above, this might be a list of words, along side known good translations in French. Small lists can be entered (or upload a CSV)."}),"\n",(0,s.jsx)("img",{alt:"image",src:"https://github.com/user-attachments/assets/6d4b1abc-bde9-4d63-9d0c-95fef60b3f9a"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"3. Create a grader that will grade LLM completions for your prompt"})}),"\n",(0,s.jsx)(t.p,{children:"Configure a grader that compares the LLM completion text with the reference output. You can use one of the out of box string evaluators, or even configure an LLM-as-a-Judge evaluator that mimics a human's grading rubric."}),"\n",(0,s.jsx)("img",{alt:"image",src:"https://github.com/user-attachments/assets/3cd510f7-c267-4cdd-bebe-dbee527a5318"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"3. Run evaluation"})}),"\n",(0,s.jsx)(t.p,{children:"Run an evaluation on a version of the prompt. You should see results in a few minutes that look like this. You can click into any row of the dataset to understand more about the evaluation for that row."}),"\n",(0,s.jsx)("img",{alt:"image",src:"https://github.com/user-attachments/assets/c450f277-b2ba-4657-b747-440b43859f20"}),"\n",(0,s.jsx)(t.p,{children:"You can categorize your dataset, and break scores out by category."}),"\n",(0,s.jsx)("img",{alt:"image",src:"https://github.com/user-attachments/assets/3c0de7c4-6721-4a45-9a61-04a63db68913"}),"\n",(0,s.jsx)(t.p,{children:"If you have scores for multiple versions, you can compare them to see what changed between versions."}),"\n",(0,s.jsx)("img",{alt:"image",src:"https://github.com/user-attachments/assets/fd593e52-ddec-4826-bf4b-c2ca1d43e4f0"})]})}function u(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,t,a)=>{a.d(t,{R:()=>i,x:()=>o});var s=a(96540);const n={},r=s.createContext(n);function i(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:i(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);