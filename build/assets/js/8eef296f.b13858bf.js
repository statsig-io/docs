"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[86760],{65898:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var i=n(74848),s=n(28453);const a={title:"Autotune (Bandits)",sidebar_label:"Introduction",slug:"/bandit-introduction",keywords:["owner:vm"],last_update:{date:new Date("2025-09-18T00:00:00.000Z")}},r=void 0,o={id:"autotune/bandit-introduction",title:"Autotune (Bandits)",description:'Multi-Armed Bandits are solutions that automatically find the best variant among a group of candidates, balancing between "exploring" options and "exploiting" the best option by dynamically allocating traffic. On Statsig, Bandits are used to pick the best user experience to drive a target metric or action.',source:"@site/docs/autotune/bandit-introduction.md",sourceDirName:"autotune",slug:"/bandit-introduction",permalink:"/bandit-introduction",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/autotune/bandit-introduction.md",tags:[],version:"current",lastUpdatedAt:17581536e5,frontMatter:{title:"Autotune (Bandits)",sidebar_label:"Introduction",slug:"/bandit-introduction",keywords:["owner:vm"],last_update:{date:"2025-09-18T00:00:00.000Z"}},sidebar:"cloud",previous:{title:"SEO Experimentation",permalink:"/guides/seo-testing"},next:{title:"Introduction",permalink:"/autotune"}},d={},l=[{value:"How Autotune works",id:"how-autotune-works",level:2}];function c(t){const e={a:"a",h2:"h2",li:"li",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...t.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.p,{children:'Multi-Armed Bandits are solutions that automatically find the best variant among a group of candidates, balancing between "exploring" options and "exploiting" the best option by dynamically allocating traffic. On Statsig, Bandits are used to pick the best user experience to drive a target metric or action.'}),"\n",(0,i.jsxs)(e.p,{children:["Statsig's ",(0,i.jsx)(e.a,{href:"/multi-armed-bandit",children:"Autotune"})," (the Multi-Armed Bandit solution) allocates traffic towards high-performing variants and can eventually identify a winning variant."]}),"\n",(0,i.jsxs)(e.p,{children:["Statsig's ",(0,i.jsx)(e.a,{href:"/contextual-bandit",children:"Autotune AI"})," (the Contextual Bandit solution) is a personalization tool that serves users the best variant determined by a machine learning model trained on previous observations."]}),"\n",(0,i.jsx)(e.h2,{id:"how-autotune-works",children:"How Autotune works"}),"\n",(0,i.jsxs)(e.p,{children:["Autotune is Statsig's ",(0,i.jsx)(e.a,{href:"/multi-armed-bandit",children:"Bayesian Multi-Armed Bandit"}),", and Autotune AI is Statsig's ",(0,i.jsx)(e.a,{href:"/contextual-bandit",children:"Contextual Bandit"}),"."]}),"\n",(0,i.jsx)(e.p,{children:"Both Autotune products will test and measure different variations and their effect on a target metric."}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"The multi-armed bandit continuously adjusts traffic towards the best performing variations until it can confidently pick the best variation. The winning variation will then receive 100% of traffic."}),"\n",(0,i.jsx)(e.li,{children:'The contextual bandit personalizes what variant a user sees based on "context" - or provided user/interaction attributes - to serve each user the variation predicted to be best (i.e. personalization).'}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:'Contextual Bandits are a subset of Multi-Armed Bandits; both seek to balance the "explore"/"exploit" problem - balancing between "exploiting" the current best known solution versus "exploring" to get more information about other solutions.'}),"\n",(0,i.jsxs)(e.p,{children:["Our blog posts on ",(0,i.jsx)(e.a,{href:"/autotune",children:"Multi-Armed Bandits"})," and ",(0,i.jsx)(e.a,{href:"https://www.statsig.com/blog/statsig-autotune-contextual-bandits-personalization",children:"Contextual Bandits"})," go into depth on use cases and considerations. The chart below describes some of the main considerations on when to use either bandits, a ranking engine, or an experiment."]}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{}),(0,i.jsx)(e.th,{children:"A/B/n Test"}),(0,i.jsx)(e.th,{children:"Multi-Armed Bandit (Autotune)"}),(0,i.jsx)(e.th,{children:"Contextual Bandit (Autotune AI)"}),(0,i.jsx)(e.th,{children:"Ranking Engine"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Typical # Variants"}),(0,i.jsx)(e.td,{children:"2-3"}),(0,i.jsx)(e.td,{children:"4-8"}),(0,i.jsx)(e.td,{children:"4-8"}),(0,i.jsx)(e.td,{children:"Arbitrary #"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Personalization Factor"}),(0,i.jsx)(e.td,{children:"None"}),(0,i.jsx)(e.td,{children:"None"}),(0,i.jsx)(e.td,{children:"Moderate"}),(0,i.jsx)(e.td,{children:"High"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Input Data Required"}),(0,i.jsx)(e.td,{children:"None"}),(0,i.jsx)(e.td,{children:"Very Little (100+ samples)"}),(0,i.jsx)(e.td,{children:"Little - generally 1000+ samples"}),(0,i.jsx)(e.td,{children:"Tens of thousands to millions of samples"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Model Efficacy"}),(0,i.jsx)(e.td,{children:"None"}),(0,i.jsx)(e.td,{children:"Basic"}),(0,i.jsx)(e.td,{children:"Moderate"}),(0,i.jsx)(e.td,{children:"High"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Identifies Best Variant"}),(0,i.jsx)(e.td,{children:"Yes"}),(0,i.jsx)(e.td,{children:"Yes"}),(0,i.jsx)(e.td,{children:"No"}),(0,i.jsx)(e.td,{children:"No"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Consistent User Assignment"}),(0,i.jsx)(e.td,{children:"Yes"}),(0,i.jsx)(e.td,{children:"No"}),(0,i.jsx)(e.td,{children:"No"}),(0,i.jsx)(e.td,{children:"No"})]})]})]})]})}function u(t={}){const{wrapper:e}={...(0,s.R)(),...t.components};return e?(0,i.jsx)(e,{...t,children:(0,i.jsx)(c,{...t})}):c(t)}},28453:(t,e,n)=>{n.d(e,{R:()=>r,x:()=>o});var i=n(96540);const s={},a=i.createContext(s);function r(t){const e=i.useContext(a);return i.useMemo((function(){return"function"==typeof t?t(e):{...e,...t}}),[e,t])}function o(t){let e;return e=t.disableParentContext?"function"==typeof t.components?t.components(s):t.components||s:r(t.components),i.createElement(a.Provider,{value:e},t.children)}}}]);