"use strict";(self.webpackChunkstatsig_docs=self.webpackChunkstatsig_docs||[]).push([[48884],{13042:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>n,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var r=t(74848),s=t(28453);const i={title:"Graders",sidebar_label:"Graders",slug:"/ai-evals/graders",keywords:["owner:vm"],last_update:{date:new Date("2025-10-01T00:00:00.000Z")}},n=void 0,o={id:"ai-evals/graders",title:"Graders",description:"What is a Grader?",source:"@site/docs/ai-evals/graders.mdx",sourceDirName:"ai-evals",slug:"/ai-evals/graders",permalink:"/ai-evals/graders",draft:!1,unlisted:!1,editUrl:"https://github.com/statsig-io/docs/edit/main/docs/ai-evals/graders.mdx",tags:[],version:"current",lastUpdatedAt:17592768e5,frontMatter:{title:"Graders",sidebar_label:"Graders",slug:"/ai-evals/graders",keywords:["owner:vm"],last_update:{date:"2025-10-01T00:00:00.000Z"}},sidebar:"cloud",previous:{title:"Prompts",permalink:"/ai-evals/prompts"},next:{title:"Offline Evals",permalink:"/ai-evals/offline-evals"}},l={},d=[{value:"What is a Grader?",id:"what-is-a-grader",level:2},{value:"What is a Critical Grader?",id:"what-is-a-critical-grader",level:2}];function c(e){const a={h2:"h2",p:"p",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.h2,{id:"what-is-a-grader",children:"What is a Grader?"}),"\n",(0,r.jsx)(a.p,{children:"A grader is the evaluation component that scores or judges the output of an AI system against a desired standard."}),"\n",(0,r.jsx)(a.p,{children:"Think of it as the core evaluation unit in the workflow:\nInputs: The grader takes in the AI model\u2019s response (and sometimes the \u201cideal\u201d or ground-truth answer if one exists).\nProcess: It applies a scoring method. This could be: Rule-based (exact string match, regex check, cosine similarity) or LLM-as-a-Judge (using another model to evaluate correctness, relevance, style, or safety)."}),"\n",(0,r.jsx)(a.p,{children:"Outputs: It produces a score - ideally 0 (Fail) or Pass (1). This score feeds into the overall Statsig experiment or eval framework to determine performance across datasets, experiments, or model versions."}),"\n",(0,r.jsx)(a.h2,{id:"what-is-a-critical-grader",children:"What is a Critical Grader?"}),"\n",(0,r.jsx)(a.p,{children:"A critical grader is a must-pass evaluation in Statsig AI Evals: if the AI output fails this grader, the entire run is marked as failed. It enforces non-negotiable requirements, acting as a hard gate before results are considered valid. When it does not fail, it acts like a normal grader."}),"\n",(0,r.jsx)(a.p,{children:"Use Case\nFor example, in a financial support chatbot, a critical grader could check that the model never fabricates account balances. Even if the answer is otherwise helpful, a single failure here blocks the model from being promoted."})]})}function u(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,a,t)=>{t.d(a,{R:()=>n,x:()=>o});var r=t(96540);const s={},i=r.createContext(s);function n(e){const a=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:n(e.components),r.createElement(i.Provider,{value:a},e.children)}}}]);